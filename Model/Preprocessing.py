import pandas as pd
import tensorflow as tf
from sklearn.model_selection import train_test_split
import pickle

if __name__ == '__main__':

    # Read the pickle file
    data = pd.read_pickle("Model/dataset.pickle")

    #Split the data into training and testing 
    x_train, xTest, y_train, yTest = train_test_split(data['Source Code'],data['Label'],test_size=0.2,random_state=1)
    
    #Split the training data into training and validation
    xTrain, xValidate, yTrain, yValidate = train_test_split(x_train,y_train,test_size=0.2,random_state=1)

    #Initialize tokenizer
    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000)
    tokenizer.fit_on_texts(list(data['Source Code']))

    #Convert training tokens into sequences
    train_tokenized = tokenizer.texts_to_sequences(xTrain)
    train_data = tf.keras.preprocessing.sequence.pad_sequences(train_tokenized,maxlen=500,padding='post')

    #Convert testing tokens into sequences
    test_tokenized = tokenizer.texts_to_sequences(xTest)
    test_data = tf.keras.preprocessing.sequence.pad_sequences(test_tokenized,maxlen=500,padding='post')
    
    #Convert validate tokens into seqeunces 
    validate_tokenized = tokenizer.texts_to_sequences(xValidate)
    validate_data = tf.keras.preprocessing.sequence.pad_sequences(validate_tokenized,maxlen=500,padding='post')

    


    